#!/usr/bin/env python3
"""
Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ pyproject.toml Ğ¸ pyproject.docker.toml
"""

import toml
import sys
from pathlib import Path

def load_toml(file_path):
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ TOML Ñ„Ğ°Ğ¹Ğ»"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return toml.load(f)
    except FileNotFoundError:
        print(f"âŒ Ğ¤Ğ°Ğ¹Ğ» {file_path} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
        return None
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ {file_path}: {e}")
        return None

def save_toml(data, file_path):
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ TOML Ñ„Ğ°Ğ¹Ğ»"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            toml.dump(data, f)
        return True
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ {file_path}: {e}")
        return False

def get_production_dependencies():
    """Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½ÑƒĞ¶Ğ½Ñ‹ Ğ² Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ğµ"""
    return {
        # Django Core
        'django',
        'djangorestframework-simplejwt',
        'django-filter',
        'django-cors-headers',
        'drf-yasg',
        
        # Database
        'psycopg2',
        
        # WebSockets & Channels
        'channels',
        'channels-redis',
        'djangochannelsrestframework',
        'daphne',
        
        # Task Queue
        'celery',
        'django-celery-beat',
        'pika',
        
        # Configuration
        'python-dotenv',
        'pytz',
        
        # Validation & Serialization
        'pydantic',
        'orjson',
        
        # HTTP & Networking
        'requests',
        'httpx',
        
        # Security
        'cryptography',
        
        # File Processing
        'pillow',
        'lxml',
        'beautifulsoup4',
        'markdown',
        'chardet',
        'python-dateutil',
        'dateparser',
        
        # AI & LangChain (Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ)
        'langchain',
        'langchain-core',
        'langchain-community',
        'langchain-tavily',
        'langchain-openai',
        'langgraph',
        'tavily-python',
        'g4f',
        
        # Translation
        'deep_translator',
        
        # Logging
        'loguru',
        
        # WSGI Server
        'gunicorn',
    }

def sync_dependencies():
    """Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸"""
    backend_dir = Path(__file__).parent.parent
    full_toml_path = backend_dir / 'pyproject.toml'
    docker_toml_path = backend_dir / 'pyproject.docker.toml'
    
    print("ğŸ”„ Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹...")
    print(f"ğŸ“ ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: {full_toml_path}")
    print(f"ğŸ³ Docker Ğ²ĞµÑ€ÑĞ¸Ñ: {docker_toml_path}")
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    full_data = load_toml(full_toml_path)
    docker_data = load_toml(docker_toml_path)
    
    if not full_data or not docker_data:
        return False
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ğ°
    prod_deps = get_production_dependencies()
    full_deps = full_data.get('tool', {}).get('poetry', {}).get('dependencies', {})
    
    # ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Docker Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    docker_deps = {}
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Python Ğ²ĞµÑ€ÑĞ¸Ñ
    if 'python' in full_deps:
        docker_deps['python'] = full_deps['python']
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    added_count = 0
    skipped_count = 0
    
    for dep_name in sorted(prod_deps):
        if dep_name in full_deps:
            docker_deps[dep_name] = full_deps[dep_name]
            added_count += 1
        else:
            print(f"âš ï¸  Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ {dep_name} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ² Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸")
            skipped_count += 1
    
    # ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Docker Ñ„Ğ°Ğ¹Ğ»
    docker_data['tool']['poetry']['dependencies'] = docker_deps
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ
    if save_toml(docker_data, docker_toml_path):
        print(f"âœ… Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!")
        print(f"ğŸ“Š Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹: {added_count}")
        print(f"âš ï¸  ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾: {skipped_count}")
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
        total_full = len(full_deps) - 1  # -1 Ğ´Ğ»Ñ python
        total_docker = len(docker_deps) - 1  # -1 Ğ´Ğ»Ñ python
        reduction = ((total_full - total_docker) / total_full) * 100
        
        print(f"ğŸ“ˆ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:")
        print(f"   ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: {total_full} Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹")
        print(f"   Docker Ğ²ĞµÑ€ÑĞ¸Ñ: {total_docker} Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹")
        print(f"   Ğ¡Ğ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ: {reduction:.1f}%")
        
        return True
    else:
        return False

def compare_dependencies():
    """Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼Ğ¸"""
    backend_dir = Path(__file__).parent.parent
    full_toml_path = backend_dir / 'pyproject.toml'
    docker_toml_path = backend_dir / 'pyproject.docker.toml'
    
    print("ğŸ” Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹...")
    
    full_data = load_toml(full_toml_path)
    docker_data = load_toml(docker_toml_path)
    
    if not full_data or not docker_data:
        return False
    
    full_deps = set(full_data.get('tool', {}).get('poetry', {}).get('dependencies', {}).keys())
    docker_deps = set(docker_data.get('tool', {}).get('poetry', {}).get('dependencies', {}).keys())
    
    # Ğ˜ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ python Ğ¸Ğ· ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ
    full_deps.discard('python')
    docker_deps.discard('python')
    
    only_in_full = full_deps - docker_deps
    only_in_docker = docker_deps - full_deps
    common = full_deps & docker_deps
    
    print(f"ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ:")
    print(f"   ĞĞ±Ñ‰Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸: {len(common)}")
    print(f"   Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸: {len(only_in_full)}")
    print(f"   Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Docker Ğ²ĞµÑ€ÑĞ¸Ğ¸: {len(only_in_docker)}")
    
    if only_in_full:
        print(f"\nğŸ“‹ Ğ˜ÑĞºĞ»ÑÑ‡ĞµĞ½Ñ‹ Ğ¸Ğ· Docker ({len(only_in_full)}):")
        for dep in sorted(only_in_full):
            print(f"   - {dep}")
    
    if only_in_docker:
        print(f"\nâš ï¸  Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Docker ({len(only_in_docker)}):")
        for dep in sorted(only_in_docker):
            print(f"   - {dep}")
    
    return True

def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    if len(sys.argv) > 1 and sys.argv[1] == 'compare':
        compare_dependencies()
    else:
        sync_dependencies()

if __name__ == '__main__':
    main()
