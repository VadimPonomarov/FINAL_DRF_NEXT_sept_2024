"""
ChatAI integration nodes for text and image generation.
"""

import logging
from typing import List, Dict, Any, Optional
from apps.chat.types.types import AgentState, ChatMessage
import g4f
from g4f.client import Client

logger = logging.getLogger(__name__)


def _translate_to_english(text: str) -> str:
    """
    Translate text to English using simple dictionary for better image generation.
    –ò–∑–±–µ–≥–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è g4f.ChatCompletion —Ç.–∫. —Ç—Ä–µ–±—É–µ—Ç –ª–æ–≥–∏–Ω.

    Args:
        text: Text to translate

    Returns:
        English translation
    """
    try:
        # If text is already in English, return as is
        if _is_english(text):
            return text

        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (–±–µ–∑ API)
        ru_to_en_dict = {
            # –ö–æ–º–∞–Ω–¥—ã
            '—Å–æ–∑–¥–∞–π': 'create', '—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π': 'generate', '–Ω–∞—Ä–∏—Å—É–π': 'draw', '–∏–∑–æ–±—Ä–∞–∑–∏': 'depict',
            
            # –û–±—ä–µ–∫—Ç—ã –∏ —Å—É—â–µ—Å—Ç–≤–∞
            '–ø–æ—Ä—Ç—Ä–µ—Ç': 'portrait', '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ': 'image', '–∫–∞—Ä—Ç–∏–Ω–∫—É': 'picture',
            '—á–µ–ª–æ–≤–µ–∫–∞': 'person', '–º—É–∂—á–∏–Ω—ã': 'man', '–∂–µ–Ω—â–∏–Ω—ã': 'woman',
            '–∫–æ—Ç–∞': 'cat', '—Å–æ–±–∞–∫–∏': 'dog', '—Å–æ–±–∞–∫—É': 'dog', '–∫–æ—à–∫—É': 'cat',
            '–ø–µ–π–∑–∞–∂': 'landscape', '–ø—Ä–∏—Ä–æ–¥—É': 'nature', '–≥–æ—Ä–æ–¥': 'city',
            
            # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç
            '–º–æ—Ç–æ—Ü–∏–∫–ª': 'motorcycle', '–º–æ—Ç–æ—Ü–∏–∫–ª–∞': 'motorcycle',
            '—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –º–æ—Ç–æ—Ü–∏–∫–ª': 'sport motorcycle', '–≥–æ–Ω–æ—á–Ω—ã–π –º–æ—Ç–æ—Ü–∏–∫–ª': 'racing motorcycle',
            '–∞–≤—Ç–æ–º–æ–±–∏–ª—å': 'car', '–º–∞—à–∏–Ω—É': 'car', '—Å–∞–º–æ–ª–µ—Ç': 'airplane',
            
            # –¶–≤–µ—Ç–∞
            '–∫—Ä–∞—Å–Ω—ã–π': 'red', '—Å–∏–Ω–∏–π': 'blue', '–∑–µ–ª–µ–Ω—ã–π': 'green', '–∂–µ–ª—Ç—ã–π': 'yellow',
            '—á–µ—Ä–Ω—ã–π': 'black', '–±–µ–ª—ã–π': 'white', '—Å–µ—Ä—ã–π': 'gray', '–æ—Ä–∞–Ω–∂–µ–≤—ã–π': 'orange',
            '—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π': 'purple', '—Ä–æ–∑–æ–≤—ã–π': 'pink', '–∫–æ—Ä–∏—á–Ω–µ–≤—ã–π': 'brown',
            '–≥–æ–ª—É–±–æ–π': 'light blue', '—Ç–µ–º–Ω–æ-—Å–∏–Ω–∏–π': 'dark blue',
            
            # –°—Ç–∏–ª–∏
            '–≤ —Å—Ç–∏–ª–µ': 'in style of', '—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π': 'realistic', '—Ä–µ–∞–ª–∏–∑–º': 'photorealistic',
            '–∫–∞—Ä–∏–∫–∞—Ç—É—Ä–∞': 'caricature', '–∫–∞—Ä–∏–∫–∞—Ç—É—Ä–Ω—ã–π': 'caricature style',
            '–∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π': 'abstract', '–º–∏–Ω–∏–º–∞–ª–∏–∑–º': 'minimalism', '–º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π': 'minimalist',
            '—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π': 'modern', '–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π': 'classic', '–≤–∏–Ω—Ç–∞–∂–Ω—ã–π': 'vintage',
            '–∞–Ω–∏–º–µ': 'anime', '–∫–æ–º–∏–∫—Å': 'comic', '–º—É–ª—å—Ç—è—à–Ω—ã–π': 'cartoon',
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            '—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π': 'sport', '—Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è': 'sport', '—Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–µ': 'sport',
            '–∫—Ä–∞—Å–∏–≤—ã–π': 'beautiful', '–∫—Ä–∞—Å–∏–≤–∞—è': 'beautiful', '–±–æ–ª—å—à–æ–π': 'big',
            '–º–∞–ª–µ–Ω—å–∫–∏–π': 'small', '–±—ã—Å—Ç—Ä—ã–π': 'fast', '–º–æ—â–Ω—ã–π': 'powerful',
            
            # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –ª–∏—á–Ω–æ—Å—Ç–∏
            '–¥–æ–Ω–∞–ª—å–¥–∞ —Ç—Ä–∞–º–ø–∞': 'Donald Trump', '—Ç—Ä–∞–º–ø–∞': 'Trump',
        }
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –ø–æ —Å–ª–æ–≤–∞–º
        words = text.lower().split()
        translated_words = []
        
        i = 0
        while i < len(words):
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ñ—Ä–∞–∑—É –∏–∑ 2-3 —Å–ª–æ–≤
            found = False
            for phrase_len in [3, 2, 1]:
                if i + phrase_len <= len(words):
                    phrase = ' '.join(words[i:i+phrase_len])
                    if phrase in ru_to_en_dict:
                        translated_words.append(ru_to_en_dict[phrase])
                        i += phrase_len
                        found = True
                        break
            if not found:
                # –°–ª–æ–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–µ - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                translated_words.append(words[i])
                i += 1
        
        english_text = ' '.join(translated_words).strip()
        
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –ø–æ—á—Ç–∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è –∏–ª–∏ –ø—É—Å—Ç–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        if not english_text or len(english_text) < 3:
            logger.warning(f"‚ö†Ô∏è Translation too short, using original: '{text}'")
            return text
        
        logger.info(f"‚úÖ Translated (dict): '{text}' -> '{english_text}'")
        return english_text

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Translation failed: {e}, using original text")
        return text


def _translate_response_to_user_language(english_response: str, target_language: str, original_prompt: str) -> str:
    """
    Translate response back to user's language.

    Args:
        english_response: Response in English
        target_language: Target language code ('ru', 'en', etc.)
        original_prompt: Original user prompt for context

    Returns:
        Translated response
    """
    try:
        if target_language == 'en':
            return english_response

        # Create translation prompt based on target language
        if target_language == 'ru':
            translation_prompt = f"""Translate the following English response to Russian.
            Keep the same meaning and structure. The response is about image generation based on user's request: "{original_prompt}"

            English response: {english_response}

            Russian translation:"""
        else:
            # Default fallback for other languages
            translation_prompt = f"""Translate the following English response to the target language.
            Keep the same meaning and structure.

            English response: {english_response}

            Translation:"""

        response = g4f.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": translation_prompt}],
            stream=False
        )

        # Clean up the response
        translated_text = str(response).strip()
        # Remove common prefixes
        prefixes_to_remove = ["Russian translation:", "Translation:", "–ü–µ—Ä–µ–≤–æ–¥:", "–†—É—Å—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥:"]
        for prefix in prefixes_to_remove:
            if translated_text.startswith(prefix):
                translated_text = translated_text[len(prefix):].strip()

        logger.info(f"Translated response to {target_language}: '{english_response}' -> '{translated_text}'")
        return translated_text

    except Exception as e:
        logger.warning(f"Response translation failed: {e}, using original response")
        return english_response


def _is_english(text: str) -> bool:
    """Check if text is primarily in English."""
    # Simple heuristic: if text contains mostly ASCII characters and common English words
    english_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'portrait', 'image', 'picture', 'draw', 'create', 'generate', 'realistic'}
    words = text.lower().split()
    english_word_count = sum(1 for word in words if word in english_words)

    # If more than 30% are common English words, consider it English
    if len(words) > 0 and english_word_count / len(words) > 0.3:
        return True

    # Check for Cyrillic characters (Russian)
    cyrillic_count = sum(1 for char in text if '\u0400' <= char <= '\u04FF')
    return cyrillic_count == 0


def _detect_language(text: str) -> str:
    """Detect the language of the input text."""
    # Check for Cyrillic characters (Russian)
    cyrillic_count = sum(1 for char in text if '\u0400' <= char <= '\u04FF')
    if cyrillic_count > 0:
        return 'ru'

    # Default to English
    return 'en'


def _enhance_image_prompt(english_prompt: str) -> str:
    """
    Enhance the English prompt with system prompt for better image quality.
    Adds quality modifiers and clear instructions for the image generation model.
    
    Args:
        english_prompt: Basic English prompt
        
    Returns:
        Enhanced prompt with quality modifiers
    """
    try:
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –µ—â–µ –Ω–µ—Ç
        quality_keywords = ['high quality', 'detailed', '4k', '8k', 'professional', 'masterpiece']
        has_quality = any(keyword in english_prompt.lower() for keyword in quality_keywords)
        
        # –ë–∞–∑–æ–≤–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        enhanced = english_prompt.strip()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞ –≤ –∫–æ–Ω–µ—Ü
        if not has_quality:
            enhanced += ", high quality, detailed, professional photograph"
        
        logger.info(f"üé® Enhanced prompt: '{english_prompt}' -> '{enhanced}'")
        return enhanced
        
    except Exception as e:
        logger.error(f"Error enhancing prompt: {e}")
        return english_prompt


def _generate_image_response(original_prompt: str, english_prompt: str, image_url: str, user_language: str) -> str:
    """Generate image response message in the user's language - NO TEXT, only image."""
    try:
        # –¢–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ - –∫–∞—Ä—Ç–∏–Ω–∫–∞ –≥–æ–≤–æ—Ä–∏—Ç —Å–∞–º–∞ –∑–∞ —Å–µ–±—è
        response = " "  # –ü—É—Å—Ç–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        logger.info(f"Generated image response without text prompt")
        return response

    except Exception as e:
        logger.error(f"Error generating image response: {e}")
        # Fallback - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
        return " "


def _create_search_enhanced_prompt(original_query: str, search_context: str, user_language: str) -> str:
    """Create search-enhanced prompt in the user's language using translation."""
    # Create base English prompt
    english_prompt = f"""
Based on the following search results, please provide a comprehensive answer to the user's question: "{original_query}"

Search Context:
{search_context}

Please synthesize this information and provide a helpful, accurate response. Include relevant details and cite sources when appropriate.
IMPORTANT: Always respond in the same language as the user's original question.
"""

    # For now, we'll use the English prompt but add language instruction
    # The ChatAI model will handle the language matching based on the system prompt
    return english_prompt


class ChatAIService:
    """Service for ChatAI interactions."""
    
    def __init__(self):
        self.client = Client()
        self.text_model = "gpt-4"
        self.image_model = "flux-schnell"
    
    def generate_text(self, messages: List[Dict[str, str]], model: Optional[str] = None) -> str:
        """Generate text response using ChatAI."""
        try:
            response = g4f.ChatCompletion.create(
                model=model or self.text_model,
                messages=messages,
                stream=False
            )
            return str(response)
        except Exception as e:
            logger.error(f"ChatAI text generation error: {e}")
            raise
    
    def generate_image(self, prompt: str, model: Optional[str] = None) -> str:
        """Generate image using pollinations.ai with flux model - always free, no auth required."""
        try:
            import urllib.parse
            import time
            
            logger.info(f"üé® Generating image with pollinations.ai flux model: {prompt[:50]}...")
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π seed –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            seed = abs(hash(f"{prompt}_{int(time.time())}")) % 1000000
            
            # –ö–æ–¥–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è URL
            encoded_prompt = urllib.parse.quote(prompt)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ pollinations.ai —Å flux –º–æ–¥–µ–ª—å—é
            image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1024&height=1024&model=flux&enhance=true&seed={seed}&nologo=true"
            
            logger.info(f"‚úÖ Image URL generated: {image_url[:100]}...")
            return image_url
                
        except Exception as e:
            logger.error(f"‚ùå Image generation error: {e}")
            # –î–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º URL (pollinations.ai –æ—á–µ–Ω—å –Ω–∞–¥–µ–∂–Ω—ã–π)
            import urllib.parse
            encoded_prompt = urllib.parse.quote(prompt)
            return f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1024&height=1024&model=flux&nologo=true"


# Global service instance
chatai_service = ChatAIService()


def chatai_text_node(state: AgentState) -> AgentState:
    """
    Generate text response using ChatAI.
    
    Args:
        state: Current agent state
        
    Returns:
        Updated state with ChatAI response
    """
    try:
        # Prepare messages for ChatAI
        messages = []
        
        # Add system context with language matching
        system_prompt = state.context.get("system_prompt",
            "You are a helpful AI assistant. Always respond in the same language as the user's question. "
            "If the user writes in Russian, respond in Russian. If in English, respond in English."
        )
        messages.append({
            "role": "system",
            "content": system_prompt
        })
        
        # Add chat history (last 10 messages for context)
        recent_messages = state.get_recent_messages(10)
        for msg in recent_messages:
            messages.append({
                "role": msg.role,
                "content": msg.content
            })
        
        # Add current query
        messages.append({
            "role": "user",
            "content": state.query
        })
        
        # Add timestamp context
        if state.now:
            timestamp_context = f"Current time: {state.get_timestamp()}"
            if messages and messages[0]["role"] == "system":
                messages[0]["content"] += f"\n{timestamp_context}"
            else:
                messages.insert(0, {
                    "role": "system",
                    "content": timestamp_context
                })
        
        # Generate response
        response = chatai_service.generate_text(messages)
        
        # Add response to chat history
        state.add_chat_message("assistant", response)
        
        return state.model_copy(update={
            "result": response,
            "metadata": {
                **state.metadata,
                "chatai_model": chatai_service.text_model,
                "message_count": len(messages)
            }
        })
        
    except Exception as e:
        error_msg = f"ChatAI text generation error: {str(e)}"
        logger.error(error_msg)
        return state.model_copy(update={"error": error_msg})


def chatai_image_node(state: AgentState) -> AgentState:
    """
    Generate image using ChatAI flux-schnell.

    Args:
        state: Current agent state

    Returns:
        Updated state with generated image
    """
    try:
        # Extract image prompt from query or use query directly
        original_prompt = state.query

        # Detect user's language
        user_language = _detect_language(original_prompt)

        # Translate prompt to English for better image generation
        english_prompt = _translate_to_english(original_prompt)

        # Enhance prompt with quality modifiers
        english_prompt = _enhance_image_prompt(english_prompt)

        # Add custom style if specified
        if state.context.get("image_style"):
            english_prompt = f"{english_prompt}, {state.context['image_style']}"

        logger.info(f"üé® Image generation: '{original_prompt}' -> '{english_prompt}' (user_lang: {user_language})")

        # Generate image
        image_url = chatai_service.generate_image(english_prompt)
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê
        if not image_url or image_url.strip() == "":
            logger.error(f"‚ùå Image URL is EMPTY! Prompt was: '{english_prompt}'")
            image_url = chatai_service.generate_image(original_prompt)  # –ü–æ–ø—ã—Ç–∫–∞ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
            logger.warning(f"‚ö†Ô∏è Retry with original prompt, URL: {image_url[:100] if image_url else 'STILL EMPTY'}")
        
        logger.info(f"‚úÖ Generated image URL: {image_url[:150] if image_url else 'EMPTY!!!'}")

        # Store image URL
        state.images.append(image_url)

        # Create response message in user's language
        response = _generate_image_response(original_prompt, english_prompt, image_url, user_language)

        # Add to chat history
        state.add_chat_message("assistant", response, {"image_url": image_url})
        
        return state.model_copy(update={
            "result": response,
            "image_url": image_url,  # Add image_url directly to state
            "images": state.images,
            "metadata": {
                **state.metadata,
                "chatai_image_model": chatai_service.image_model,
                "original_prompt": original_prompt,
                "english_prompt": english_prompt,
                "user_language": user_language,
                "translation_used": original_prompt != english_prompt,
                "image_url": image_url  # Also add to metadata for backwards compatibility
            }
        })
        
    except Exception as e:
        error_msg = f"ChatAI image generation error: {str(e)}"
        logger.error(error_msg)
        return state.model_copy(update={"error": error_msg})


def chatai_enhanced_text_node(state: AgentState) -> AgentState:
    """
    Enhanced text generation with context awareness.
    
    Args:
        state: Current agent state
        
    Returns:
        Updated state with enhanced response
    """
    try:
        # Build enhanced system prompt
        system_parts = []
        
        # Base system prompt with language matching
        system_parts.append(
            "You are a helpful AI assistant. Provide accurate, helpful, and engaging responses. "
            "Use the conversation history and any additional context provided. "
            "IMPORTANT: Always respond in the same language as the user's question. "
            "If the user writes in Russian, respond in Russian. If in English, respond in English. "
            "Match the language of the user's input exactly."
        )
        
        # Add timestamp
        if state.now:
            system_parts.append(f"Current time: {state.get_timestamp()}")
        
        # Add data mode context
        if state.data_mode:
            if state.data_mode.value == "realtime":
                system_parts.append(
                    "Focus on providing current, up-to-date information. "
                    "If you don't have recent data, acknowledge this limitation."
                )
            else:
                system_parts.append(
                    "Use your training data to provide comprehensive responses. "
                    "You can draw from your knowledge base."
                )
        
        # Add any custom context
        if state.context.get("additional_context"):
            system_parts.append(f"Additional context: {state.context['additional_context']}")
        
        system_prompt = "\n\n".join(system_parts)
        
        # Prepare messages
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add recent chat history
        recent_messages = state.get_recent_messages(8)
        for msg in recent_messages:
            messages.append({
                "role": msg.role,
                "content": msg.content
            })
        
        # Add current query
        messages.append({
            "role": "user",
            "content": state.query
        })
        
        # Generate response
        response = chatai_service.generate_text(messages)
        
        # Add to chat history
        state.add_chat_message("assistant", response)
        
        return state.model_copy(update={
            "result": response,
            "metadata": {
                **state.metadata,
                "enhanced_generation": True,
                "system_prompt_length": len(system_prompt),
                "context_messages": len(recent_messages)
            }
        })
        
    except Exception as e:
        error_msg = f"Enhanced ChatAI generation error: {str(e)}"
        logger.error(error_msg)
        return state.model_copy(update={"error": error_msg})
