# üöÄ –ê–≤—Ç–æ–Ω–æ–º–Ω–∏–π Celery –ú—ñ–∫—Ä–æ—Å–µ—Ä–≤—ñ—Å

–ù–µ–∑–∞–ª–µ–∂–Ω–∏–π —Å–µ—Ä–≤—ñ—Å —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —á–µ—Ä–≥–∞–º–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —Ñ–æ–Ω–æ–≤–∏—Ö –∑–∞–≤–¥–∞–Ω—å.

## üìã –û–≥–ª—è–¥

–¶–µ –ø–æ–≤–Ω—ñ—Å—Ç—é –∞–≤—Ç–æ–Ω–æ–º–Ω–∏–π Celery –º—ñ–∫—Ä–æ—Å–µ—Ä–≤—ñ—Å, —è–∫–∏–π –æ–±—Ä–æ–±–ª—è—î:
- ‚úâÔ∏è –í—ñ–¥–ø—Ä–∞–≤–∫–∞ email —Ç–∞ –º–∞—Å–æ–≤—ñ email –æ–ø–µ—Ä–∞—Ü—ñ—ó
- üì± Push —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è —Ç–∞ SMS
- üîÑ –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö —Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤
- üßπ –û—á–∏—â–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ —Ç–∞ –∑–∞–≤–¥–∞–Ω–Ω—è –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è

## üèóÔ∏è –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```
celery-service/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ celery_app.py          # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è Celery –¥–æ–¥–∞—Ç–∫—É
‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ email_tasks.py         # –ó–∞–≤–¥–∞–Ω–Ω—è –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ email
‚îÇ   ‚îú‚îÄ‚îÄ notification_tasks.py  # Push —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è, SMS
‚îÇ   ‚îú‚îÄ‚îÄ data_processing_tasks.py # –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö, –∑–≤—ñ—Ç–∏
‚îÇ   ‚îî‚îÄ‚îÄ cleanup_tasks.py       # –û–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏
‚îú‚îÄ‚îÄ core/                      # –°–ø—ñ–ª—å–Ω—ñ —É—Ç–∏–ª—ñ—Ç–∏ (–∑–∞ –ø–æ—Ç—Ä–µ–±–∏)
‚îú‚îÄ‚îÄ logs/                      # –§–∞–π–ª–∏ –ª–æ–≥—ñ–≤
‚îú‚îÄ‚îÄ Dockerfile                 # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
‚îú‚îÄ‚îÄ docker-compose.yml         # –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü—ñ—è —Å–µ—Ä–≤—ñ—Å—ñ–≤
‚îú‚îÄ‚îÄ pyproject.toml            # –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
‚îú‚îÄ‚îÄ .env.example              # –®–∞–±–ª–æ–Ω –æ—Ç–æ—á–µ–Ω–Ω—è
‚îú‚îÄ‚îÄ main.py                   # –¢–æ—á–∫–∞ –≤—Ö–æ–¥—É
‚îî‚îÄ‚îÄ README.md                 # –¶–µ–π —Ñ–∞–π–ª
```

## üöÄ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### 1. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –æ—Ç–æ—á–µ–Ω–Ω—è

```bash
# –ö–æ–ø—ñ—é–≤–∞—Ç–∏ —à–∞–±–ª–æ–Ω –æ—Ç–æ—á–µ–Ω–Ω—è
cp .env.example .env

# –†–µ–¥–∞–≥—É–≤–∞—Ç–∏ –∑–º—ñ–Ω–Ω—ñ –æ—Ç–æ—á–µ–Ω–Ω—è
nano .env
```

### 2. –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤—ñ—Å—ñ–≤

```bash
# Start all services (Redis, RabbitMQ, Celery workers, Flower)
docker-compose up -d

# View logs
docker-compose logs -f celery-worker

# Check status
docker-compose ps
```

### 3. Monitor with Flower

Open http://localhost:5555 to access Flower monitoring interface.

## üì° Available Tasks

### Email Tasks
- `send_email_task` - Send individual email
- `send_bulk_email_task` - Send bulk emails
- `send_notification_to_backend` - Notify main backend

### Notification Tasks
- `send_push_notification_task` - Send push notifications
- `send_sms_task` - Send SMS messages
- `process_notification_queue_task` - Process notification batches

### Data Processing Tasks
- `process_user_data_task` - Process user data
- `generate_report_task` - Generate reports
- `batch_data_import_task` - Import data files

### Cleanup Tasks
- `cleanup_temp_files_task` - Clean temporary files
- `cleanup_old_logs_task` - Clean old log files
- `system_health_check_task` - System health monitoring
- `daily_maintenance_task` - Daily maintenance routine

## üîß Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `RABBITMQ_HOST` | RabbitMQ hostname | `rabbitmq` |
| `RABBITMQ_PORT` | RabbitMQ port | `5672` |
| `REDIS_HOST` | Redis hostname | `redis` |
| `REDIS_PORT` | Redis port | `6379` |
| `BACKEND_API_URL` | Main backend URL | `http://app:8000` |
| `SMTP_HOST` | SMTP server | `localhost` |
| `FCM_SERVER_KEY` | Firebase key | - |

### Queue Configuration

- `email` - Email sending tasks
- `notifications` - Push notifications, SMS
- `data_processing` - Data processing, reports
- `cleanup` - System maintenance

## üîó Integration with Main Backend

### Using Celery Client

```python
from core.celery_client import celery_client

# Send email
task_id = celery_client.send_email(
    to_email="user@example.com",
    subject="Welcome!",
    body="Welcome to our service!"
)

# Send push notification
task_id = celery_client.send_push_notification(
    user_tokens=["fcm_token_1", "fcm_token_2"],
    title="New Message",
    body="You have a new message"
)

# Process user data
task_id = celery_client.process_user_data(
    user_id=123,
    data_type="profile_update",
    data={"name": "John Doe"}
)

# Check task status
status = celery_client.get_task_status(task_id)
result = celery_client.get_task_result(task_id)
```

### API Endpoints (if needed)

The microservice can expose REST API endpoints for task management:

```bash
# Queue email task
POST /api/tasks/email/
{
    "to_email": "user@example.com",
    "subject": "Test",
    "body": "Test message"
}

# Get task status
GET /api/tasks/{task_id}/status/

# Get task result
GET /api/tasks/{task_id}/result/
```

## üìä Monitoring

### Flower Dashboard
- URL: http://localhost:5555
- Monitor active tasks, workers, queues
- View task history and results

### Health Checks
- Worker health: `celery -A config.celery_app inspect ping`
- Queue status: `celery -A config.celery_app inspect active_queues`
- System health: Automatic health check tasks

### Logs
- Application logs: `./logs/celery-microservice.log`
- Worker logs: `docker-compose logs celery-worker`
- Beat logs: `docker-compose logs celery-beat`

## üîÑ Scaling

### Horizontal Scaling

```bash
# Scale workers
docker-compose up -d --scale celery-worker=3

# Scale specific queue workers
docker-compose run -d celery-worker celery -A config.celery_app worker --queues=email --concurrency=4
```

### Queue-Specific Workers

```bash
# Email-only worker
celery -A config.celery_app worker --queues=email --concurrency=2

# Data processing worker
celery -A config.celery_app worker --queues=data_processing --concurrency=1

# Cleanup worker
celery -A config.celery_app worker --queues=cleanup --concurrency=1
```

## üõ†Ô∏è Development

### Local Development

```bash
# Install dependencies
poetry install

# Start Redis and RabbitMQ
docker-compose up -d redis rabbitmq

# Start worker locally
celery -A config.celery_app worker --loglevel=info

# Start beat scheduler
celery -A config.celery_app beat --loglevel=info

# Start flower monitoring
celery -A config.celery_app flower
```

### Testing

```bash
# Run tests
poetry run pytest

# Test specific task
python -c "
from config.celery_app import app
result = app.send_task('tasks.email_tasks.send_email_task', 
                      args=['test@example.com', 'Test', 'Test message'])
print(f'Task ID: {result.id}')
"
```

## üîí Security

- Non-root user in container
- Environment variable configuration
- API key authentication for backend communication
- Network isolation with Docker networks

## üìà Performance

- Optimized for minimal resource usage
- Configurable worker concurrency
- Memory limits per worker
- Task result expiration
- Connection pooling

## üö® Troubleshooting

### Common Issues

1. **Connection refused to RabbitMQ/Redis**
   ```bash
   # Check service status
   docker-compose ps
   
   # Check logs
   docker-compose logs rabbitmq redis
   ```

2. **Tasks not executing**
   ```bash
   # Check worker status
   celery -A config.celery_app inspect active
   
   # Check queue status
   celery -A config.celery_app inspect active_queues
   ```

3. **Memory issues**
   ```bash
   # Monitor memory usage
   docker stats celery-worker
   
   # Adjust worker settings in .env
   CELERY_MAX_MEMORY_PER_CHILD=200000
   ```

## üìù License

This microservice is part of the main application and follows the same license terms.

## ‚è∞ –ü–µ—Ä—ñ–æ–¥–∏—á–Ω—ñ –∑–∞–¥–∞—á—ñ (celery-beat)

Celery Beat –∑–∞–ø—É—Å–∫–∞—î –∑–∞–¥–∞—á—ñ –∑–∞ —Ä–æ–∑–∫–ª–∞–¥–æ–º (cron/—ñ–Ω—Ç–µ—Ä–≤–∞–ª–∏) —ñ —Å—Ç–∞–≤–∏—Ç—å —ó—Ö —É —á–µ—Ä–≥—É –¥–ª—è –≤–æ—Ä–∫–µ—Ä—ñ–≤.

### –Ø–∫ —Ü–µ –ø—Ä–∞—Ü—é—î –≤ –ø—Ä–æ–µ–∫—Ç—ñ

- –ü–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫: `celery -A config.celery_app beat`
- –í–æ—Ä–∫–µ—Ä(–∏): `celery -A config.celery_app worker -l info -Q email,notifications,data_processing,cleanup`
- –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥: Flower `http://localhost:5555`

### –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —Ä–æ–∑–∫–ª–∞–¥—É

```python
# celery-service/config/celery_app.py
from celery.schedules import crontab
from celery import Celery

app = Celery("celery_service")
# ... —ñ–Ω—à–∏–π –∫–æ–Ω—Ñ—ñ–≥ ...

app.conf.beat_schedule = {
    # 1) –©–æ–¥–µ–Ω–Ω–∏–π –±–µ–∫–∞–ø –ë–î –æ 02:00
    "daily-db-backup": {
        "task": "tasks.cleanup_tasks.daily_maintenance_task",
        "schedule": crontab(hour=2, minute=0),
        "options": {"queue": "cleanup"},
    },
    # 2) –û–Ω–æ–≤–ª–µ–Ω–Ω—è –∫—É—Ä—Å—ñ–≤ –≤–∞–ª—é—Ç —â–æ–≥–æ–¥–∏–Ω–∏ (–¥–ª—è AutoRia)
    "update-exchange-rates-hourly": {
        "task": "tasks.data_processing_tasks.update_exchange_rates_task",
        "schedule": crontab(minute=0),
        "options": {"queue": "data_processing"},
    },
    # 3) –ù–∞–¥—Å–∏–ª–∞–Ω–Ω—è –¥–∞–π–¥–∂–µ—Å—Ç—É email —â–æ–¥–µ–Ω–Ω–æ –æ 08:00
    "send-daily-email-digest": {
        "task": "tasks.email_tasks.send_daily_digest_task",
        "schedule": crontab(hour=8, minute=0),
        "options": {"queue": "email"},
    },
    # 4) Health-check —Å–µ—Ä–≤—ñ—Å—ñ–≤ –∫–æ–∂–Ω—ñ 5 —Ö–≤–∏–ª–∏–Ω
    "system-health-check": {
        "task": "tasks.cleanup_tasks.system_health_check_task",
        "schedule": crontab(minute="*/5"),
        "options": {"queue": "cleanup"},
    },
}
```

### –ü—Ä–∏–∫–ª–∞–¥–∏ –∑–∞–¥–∞—á

```python
# celery-service/tasks/email_tasks.py
from celery import shared_task
from core.http import http_post

@shared_task(name="tasks.email_tasks.send_daily_digest_task")
def send_daily_digest_task():
    # –ó–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –∑ –±–µ–∫–µ–Ω–¥—É
    http_post("/internal/reports/daily-digest/trigger")
    return "daily digest triggered"
```

```python
# celery-service/tasks/data_processing_tasks.py
from celery import shared_task
from core.http import http_post

@shared_task(name="tasks.data_processing_tasks.update_exchange_rates_task")
def update_exchange_rates_task():
    # –í–∏–∫–ª–∏–∫–∞—î–º–æ –±–µ–∫–µ–Ω–¥ –µ–Ω–¥–ø–æ—ñ–Ω—Ç –¥–ª—è –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∫—É—Ä—Å—ñ–≤
    http_post("/internal/exchange-rates/update")
    return "exchange rates update scheduled"
```

```python
# celery-service/tasks/cleanup_tasks.py
from celery import shared_task
from core.http import http_get

@shared_task(name="tasks.cleanup_tasks.system_health_check_task")
def system_health_check_task():
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤'—è –ø–æ–≤'—è–∑–∞–Ω–∏—Ö —Å–µ—Ä–≤—ñ—Å—ñ–≤
    services = [
        "/health/redis",
        "/health/rabbitmq",
        "/health/postgres",
        "/health/search-index",
    ]
    results = {path: http_get(path).status_code for path in services}
    return results
```

### –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –ø–æ–≤‚Äô—è–∑–∞–Ω—ñ —Å–µ—Ä–≤—ñ—Å–∏

- Backend (Django API): `http://app:8000`
  - `/internal/reports/daily-digest/trigger` ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–π–¥–∂–µ—Å—Ç—É
  - `/internal/exchange-rates/update` ‚Äî –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∫—É—Ä—Å—ñ–≤ –≤–∞–ª—é—Ç
  - `/health/*` ‚Äî –µ–Ω–¥–ø–æ—ñ–Ω—Ç–∏ –∑–¥–æ—Ä–æ–≤'—è —Å–µ—Ä–≤—ñ—Å—ñ–≤ (internal)
- RabbitMQ (–±—Ä–æ–∫–µ—Ä): `amqp://rabbitmq:5672`
- Redis (—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏/–±—Ä–æ–∫–µ—Ä, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ): `redis://redis:6379/0`
- Flower (–º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥): `http://flower:5555`

### –ó–∞–ø—É—Å–∫ —É Docker Compose

```yaml
# docker-compose.yml (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)
services:
  celery-worker:
    build: ./celery-service
    command: celery -A config.celery_app worker -l info -Q email,notifications,data_processing,cleanup
    depends_on: [rabbitmq, redis, app]

  celery-beat:
    build: ./celery-service
    command: celery -A config.celery_app beat -l info
    depends_on: [rabbitmq, redis, app]

  flower:
    image: mher/flower
    command: flower --broker=amqp://guest:guest@rabbitmq:5672//
    ports: ["5555:5555"]
    depends_on: [rabbitmq]
```

### Best Practices

- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –æ–∫—Ä–µ–º—ñ —á–µ—Ä–≥–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤ –∑–∞–¥–∞—á (`email`, `cleanup`, `data_processing`)
- –°—Ç–∞–≤—Ç–µ —ñ–¥empotent –ª–æ–≥—ñ–∫—É —É –ø–µ—Ä—ñ–æ–¥–∏—á–Ω—ñ –∑–∞–¥–∞—á—ñ
- –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É –ë–î/ELK –¥–ª—è –∞—É–¥–∏—Ç—É
- –û–±–º–µ–∂—É–π—Ç–µ runtime (soft/hard time limits) –¥–ª—è –≤–∞–∂–∫–∏—Ö –∑–∞–¥–∞—á
- –ü–µ—Ä–µ–≤—ñ—Ä—è–π—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ñ—Å—Ç—å –∑–∞–ª–µ–∂–Ω–∏—Ö —Å–µ—Ä–≤—ñ—Å—ñ–≤ –ø–µ—Ä–µ–¥ –≤–∏–∫–ª–∏–∫–æ–º