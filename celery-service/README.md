# üöÄ –ê–≤—Ç–æ–Ω–æ–º–Ω–∏–π Celery –ú—ñ–∫—Ä–æ—Å–µ—Ä–≤—ñ—Å

–ù–µ–∑–∞–ª–µ–∂–Ω–∏–π —Å–µ—Ä–≤—ñ—Å —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —á–µ—Ä–≥–∞–º–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —Ñ–æ–Ω–æ–≤–∏—Ö –∑–∞–≤–¥–∞–Ω—å.

## üìã –û–≥–ª—è–¥

–¶–µ –ø–æ–≤–Ω—ñ—Å—Ç—é –∞–≤—Ç–æ–Ω–æ–º–Ω–∏–π Celery –º—ñ–∫—Ä–æ—Å–µ—Ä–≤—ñ—Å, —è–∫–∏–π –æ–±—Ä–æ–±–ª—è—î:
- ‚úâÔ∏è –í—ñ–¥–ø—Ä–∞–≤–∫–∞ email —Ç–∞ –º–∞—Å–æ–≤—ñ email –æ–ø–µ—Ä–∞—Ü—ñ—ó
- üì± Push —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è —Ç–∞ SMS
- üîÑ –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö —Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤
- üßπ –û—á–∏—â–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ —Ç–∞ –∑–∞–≤–¥–∞–Ω–Ω—è –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è

## üèóÔ∏è –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```
celery-service/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ celery_app.py          # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è Celery –¥–æ–¥–∞—Ç–∫—É
‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ email_tasks.py         # –ó–∞–≤–¥–∞–Ω–Ω—è –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ email
‚îÇ   ‚îú‚îÄ‚îÄ notification_tasks.py  # Push —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è, SMS
‚îÇ   ‚îú‚îÄ‚îÄ data_processing_tasks.py # –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö, –∑–≤—ñ—Ç–∏
‚îÇ   ‚îî‚îÄ‚îÄ cleanup_tasks.py       # –û–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏
‚îú‚îÄ‚îÄ core/                      # –°–ø—ñ–ª—å–Ω—ñ —É—Ç–∏–ª—ñ—Ç–∏ (–∑–∞ –ø–æ—Ç—Ä–µ–±–∏)
‚îú‚îÄ‚îÄ logs/                      # –§–∞–π–ª–∏ –ª–æ–≥—ñ–≤
‚îú‚îÄ‚îÄ Dockerfile                 # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
‚îú‚îÄ‚îÄ docker-compose.yml         # –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü—ñ—è —Å–µ—Ä–≤—ñ—Å—ñ–≤
‚îú‚îÄ‚îÄ pyproject.toml            # –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
‚îú‚îÄ‚îÄ .env.example              # –®–∞–±–ª–æ–Ω –æ—Ç–æ—á–µ–Ω–Ω—è
‚îú‚îÄ‚îÄ main.py                   # –¢–æ—á–∫–∞ –≤—Ö–æ–¥—É
‚îî‚îÄ‚îÄ README.md                 # –¶–µ–π —Ñ–∞–π–ª
```

## üöÄ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### 1. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –æ—Ç–æ—á–µ–Ω–Ω—è

```bash
# –ö–æ–ø—ñ—é–≤–∞—Ç–∏ —à–∞–±–ª–æ–Ω –æ—Ç–æ—á–µ–Ω–Ω—è
cp .env.example .env

# –†–µ–¥–∞–≥—É–≤–∞—Ç–∏ –∑–º—ñ–Ω–Ω—ñ –æ—Ç–æ—á–µ–Ω–Ω—è
nano .env
```

### 2. –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤—ñ—Å—ñ–≤

```bash
# Start all services (Redis, RabbitMQ, Celery workers, Flower)
docker-compose up -d

# View logs
docker-compose logs -f celery-worker

# Check status
docker-compose ps
```

### 3. Monitor with Flower

Open http://localhost:5555 to access Flower monitoring interface.

## üì° Available Tasks

### Email Tasks
- `send_email_task` - Send individual email
- `send_bulk_email_task` - Send bulk emails
- `send_notification_to_backend` - Notify main backend

### Notification Tasks
- `send_push_notification_task` - Send push notifications
- `send_sms_task` - Send SMS messages
- `process_notification_queue_task` - Process notification batches

### Data Processing Tasks
- `process_user_data_task` - Process user data
- `generate_report_task` - Generate reports
- `batch_data_import_task` - Import data files

### Cleanup Tasks
- `cleanup_temp_files_task` - Clean temporary files
- `cleanup_old_logs_task` - Clean old log files
- `system_health_check_task` - System health monitoring
- `daily_maintenance_task` - Daily maintenance routine

## üîß Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `RABBITMQ_HOST` | RabbitMQ hostname | `rabbitmq` |
| `RABBITMQ_PORT` | RabbitMQ port | `5672` |
| `REDIS_HOST` | Redis hostname | `redis` |
| `REDIS_PORT` | Redis port | `6379` |
| `BACKEND_API_URL` | Main backend URL | `http://app:8000` |
| `SMTP_HOST` | SMTP server | `localhost` |
| `FCM_SERVER_KEY` | Firebase key | - |

### Queue Configuration

- `email` - Email sending tasks
- `notifications` - Push notifications, SMS
- `data_processing` - Data processing, reports
- `cleanup` - System maintenance

## üîó Integration with Main Backend

### Using Celery Client

```python
from core.celery_client import celery_client

# Send email
task_id = celery_client.send_email(
    to_email="user@example.com",
    subject="Welcome!",
    body="Welcome to our service!"
)

# Send push notification
task_id = celery_client.send_push_notification(
    user_tokens=["fcm_token_1", "fcm_token_2"],
    title="New Message",
    body="You have a new message"
)

# Process user data
task_id = celery_client.process_user_data(
    user_id=123,
    data_type="profile_update",
    data={"name": "John Doe"}
)

# Check task status
status = celery_client.get_task_status(task_id)
result = celery_client.get_task_result(task_id)
```

### API Endpoints (if needed)

The microservice can expose REST API endpoints for task management:

```bash
# Queue email task
POST /api/tasks/email/
{
    "to_email": "user@example.com",
    "subject": "Test",
    "body": "Test message"
}

# Get task status
GET /api/tasks/{task_id}/status/

# Get task result
GET /api/tasks/{task_id}/result/
```

## üìä Monitoring

### Flower Dashboard
- URL: http://localhost:5555
- Monitor active tasks, workers, queues
- View task history and results

### Health Checks
- Worker health: `celery -A config.celery_app inspect ping`
- Queue status: `celery -A config.celery_app inspect active_queues`
- System health: Automatic health check tasks

### Logs
- Application logs: `./logs/celery-microservice.log`
- Worker logs: `docker-compose logs celery-worker`
- Beat logs: `docker-compose logs celery-beat`

## üîÑ Scaling

### Horizontal Scaling

```bash
# Scale workers
docker-compose up -d --scale celery-worker=3

# Scale specific queue workers
docker-compose run -d celery-worker celery -A config.celery_app worker --queues=email --concurrency=4
```

### Queue-Specific Workers

```bash
# Email-only worker
celery -A config.celery_app worker --queues=email --concurrency=2

# Data processing worker
celery -A config.celery_app worker --queues=data_processing --concurrency=1

# Cleanup worker
celery -A config.celery_app worker --queues=cleanup --concurrency=1
```

## üõ†Ô∏è Development

### Local Development

```bash
# Install dependencies
poetry install

# Start Redis and RabbitMQ
docker-compose up -d redis rabbitmq

# Start worker locally
celery -A config.celery_app worker --loglevel=info

# Start beat scheduler
celery -A config.celery_app beat --loglevel=info

# Start flower monitoring
celery -A config.celery_app flower
```

### Testing

```bash
# Run tests
poetry run pytest

# Test specific task
python -c "
from config.celery_app import app
result = app.send_task('tasks.email_tasks.send_email_task', 
                      args=['test@example.com', 'Test', 'Test message'])
print(f'Task ID: {result.id}')
"
```

## üîí Security

- Non-root user in container
- Environment variable configuration
- API key authentication for backend communication
- Network isolation with Docker networks

## üìà Performance

- Optimized for minimal resource usage
- Configurable worker concurrency
- Memory limits per worker
- Task result expiration
- Connection pooling

## üö® Troubleshooting

### Common Issues

1. **Connection refused to RabbitMQ/Redis**
   ```bash
   # Check service status
   docker-compose ps
   
   # Check logs
   docker-compose logs rabbitmq redis
   ```

2. **Tasks not executing**
   ```bash
   # Check worker status
   celery -A config.celery_app inspect active
   
   # Check queue status
   celery -A config.celery_app inspect active_queues
   ```

3. **Memory issues**
   ```bash
   # Monitor memory usage
   docker stats celery-worker
   
   # Adjust worker settings in .env
   CELERY_MAX_MEMORY_PER_CHILD=200000
   ```

## üìù License

This microservice is part of the main application and follows the same license terms.
