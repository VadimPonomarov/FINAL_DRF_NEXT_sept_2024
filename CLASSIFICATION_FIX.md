# üêõ –ü—Ä–æ–±–ª–µ–º–∞ —Å –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π Intent

## –°–∏–º–ø—Ç–æ–º
–ó–∞–ø—Ä–æ—Å "—Å–ø–∞—Ä—Å–∏ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å https://kurs.com.ua" –ø–æ–ø–∞–¥–∞–µ—Ç –≤ **IMAGE_GENERATION** –≤–º–µ—Å—Ç–æ **WEB_CRAWLING**

## –ü—Ä–∏—á–∏–Ω–∞
G4F –º–æ–¥–µ–ª—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤ `intelligent_classifier.py`

## –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
1. ‚úÖ –ì—Ä–∞—Ñ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π: `Intent.WEB_CRAWLING ‚Üí crawl4ai_ask`
2. ‚úÖ –ü—Ä–∏–º–µ—Ä—ã –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ: `"–°–ø–∞—Ä—Å—å –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å https://example.com" ‚Üí WEB_CRAWLING`
3. ‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–∏—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Ç–∞–±–ª–∏—Ü—ã —Å –∫—É—Ä—Å–∞–º–∏

## –†–µ—à–µ–Ω–∏–µ

### –í–∞—Ä–∏–∞–Ω—Ç 1: –£–ª—É—á—à–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã (QUICK FIX)
–î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —è–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫—É—Ä—Å–æ–≤:

```python
**Examples:**
- "—Å–ø–∞—Ä—Å–∏ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å https://kurs.com.ua" ‚Üí WEB_CRAWLING + REALTIME  
- "—Å–ø–∞—Ä—Å—å –∫—É—Ä—Å—ã —Å —Å–∞–π—Ç–∞" ‚Üí WEB_CRAWLING + REALTIME
- "–ø–æ–∫–∞–∂–∏ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å kurs.com.ua" ‚Üí WEB_CRAWLING + REALTIME
- "–∏–∑–≤–ª–µ–∫–∏ –∫—É—Ä—Å—ã —Å https://kurs.com.ua" ‚Üí WEB_CRAWLING + REALTIME
- "–°–ø–∞—Ä—Å—å –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å https://example.com" ‚Üí WEB_CRAWLING + REALTIME
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (FAILSAFE)
–î–æ–±–∞–≤–∏—Ç—å —è–≤–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä:

```python
def classify(self, query: str) -> IntentClassification:
    query_lower = query.lower()
    
    # FAILSAFE: Explicit URL crawling patterns
    crawl_patterns = ['—Å–ø–∞—Ä—Å', '–ø–∞—Ä—Å', '–∏–∑–≤–ª–µ—á', 'crawl', 'scrape', 'extract']
    has_url = 'http' in query_lower or 'www.' in query_lower
    
    if has_url and any(pattern in query_lower for pattern in crawl_patterns):
        logger.info(f"üéØ FAILSAFE: Detected URL crawling pattern")
        return IntentClassification(
            intent=Intent.WEB_CRAWLING,
            data_mode=DataMode.REALTIME,
            confidence=0.95,
            reasoning="URL crawling pattern detected (failsafe)"
        )
    
    # Continue with LLM classification...
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: Upgrade G4F (LONG TERM)
–û–±–Ω–æ–≤–∏—Ç—å g4f –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏:
```bash
pip install -U g4f
# Current: 0.5.7.6
# Available: 0.6.4.3
```

## –ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –î–µ–π—Å—Ç–≤–∏—è

1. **–î–æ–±–∞–≤–∏—Ç—å failsafe –ø—Ä–æ–≤–µ—Ä–∫—É** –≤ `intelligent_classifier.py`
2. **–î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤** –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫—É—Ä—Å–æ–≤
3. **–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é** –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

## –ö–æ–¥ –¥–ª—è –í–Ω–µ–¥—Ä–µ–Ω–∏—è

```python
# –í intelligent_classifier.py, –º–µ—Ç–æ–¥ classify():

def classify(self, query: str) -> IntentClassification:
    """Classify with failsafe for URL crawling."""
    
    # FAILSAFE for URL crawling
    query_lower = query.lower()
    crawl_keywords = ['—Å–ø–∞—Ä—Å', '–ø–∞—Ä—Å', 'extract', 'crawl', 'scrape', '–∫—É—Ä—Å', '—Ü–µ–Ω']
    has_url = bool(re.search(r'https?://|www\.', query))
    
    if has_url:
        # Check for crawling intent
        if any(kw in query_lower for kw in ['—Å–ø–∞—Ä—Å', '–ø–∞—Ä—Å', 'extract', 'crawl']):
            logger.warning(f"üéØ FAILSAFE ROUTE: URL + parsing keyword ‚Üí WEB_CRAWLING")
            return IntentClassification(
                intent=Intent.WEB_CRAWLING,
                data_mode=DataMode.REALTIME,
                confidence=0.95,
                reasoning="Failsafe: URL parsing pattern detected"
            )
        
        # Check for currency/price extraction
        if any(kw in query_lower for kw in ['–∫—É—Ä—Å', '–≤–∞–ª—é—Ç', '—Ü–µ–Ω', 'price', 'rate']):
            logger.warning(f"üéØ FAILSAFE ROUTE: URL + currency/price ‚Üí WEB_CRAWLING")
            return IntentClassification(
                intent=Intent.WEB_CRAWLING,
                data_mode=DataMode.REALTIME,
                confidence=0.95,
                reasoning="Failsafe: Currency/price extraction from URL"
            )
    
    # Continue with LLM classification...
    return self._llm_classify(query)
```

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
# Test cases
test_queries = [
    "—Å–ø–∞—Ä—Å–∏ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å https://kurs.com.ua",
    "—Å–ø–∞—Ä—Å—å –∫—É—Ä—Å—ã —Å https://minfin.com.ua",
    "–∏–∑–≤–ª–µ–∫–∏ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å kurs.com.ua",
    "–ø–æ–∫–∞–∂–∏ –∫—É—Ä—Å—ã —Å https://example.com",
]

for query in test_queries:
    result = classifier.classify(query)
    assert result.intent == Intent.WEB_CRAWLING, f"Failed for: {query}"
    print(f"‚úÖ {query} ‚Üí {result.intent}")
```

## –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: üî¥ CRITICAL
–ë–µ–∑ —ç—Ç–æ–≥–æ —Ñ–∏–∫—Å–∞ –∫—Ä–∞—É–ª–µ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!

